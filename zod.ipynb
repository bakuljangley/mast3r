{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import the ZOD DevKit\n",
    "from zod import ZodFrames\n",
    "from zod import ZodSequences\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# import default constants\n",
    "import zod.constants as constants\n",
    "from zod.constants import Camera, Lidar, Anonymization, AnnotationProject\n",
    "\n",
    "# import useful data classes\n",
    "from zod.data_classes import LidarData\n",
    "\n",
    "#for loading zod data\n",
    "zod_dataset = \"/home/bjangley/VPR/ZOD/full\"  # your local path to zod\n",
    "version = \"mini\"  # \"mini\" or \"full\"\n",
    "\n",
    "# initialize ZodSequences\n",
    "zod_sequences = ZodSequences(dataset_root=zod_dataset, version=version)\n",
    "zod_000002 = zod_sequences['000002'] #getting a specific sequence\n",
    "\n",
    "#for mapillary data\n",
    "mapillary_metadata = '/home/bjangley/VPR/mapillary_utils/zod_000002/metadata.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    r = 6371000  # Radius of Earth in meter\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    return r * c\n",
    "\n",
    "def sort_images_by_distance(csv_file_path, target_lat, target_lng):\n",
    "    images = []\n",
    "    \n",
    "    with open(csv_file_path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            lat = float(row['lat'])\n",
    "            lng = float(row['long'])\n",
    "            distance = haversine(target_lat, target_lng, lat, lng)\n",
    "            images.append({'image_id': row['id'], 'distance': distance})\n",
    "    \n",
    "    return sorted(images, key=lambda x: x['distance'])\n",
    "\n",
    "\n",
    "#sorting mapillary images based on their distance to the keyframe\n",
    "\n",
    "keyframe_lat = zod_000002.metadata.latitude\n",
    "keyframe_lon = zod_000002.metadata.longitude\n",
    "sorted_images = sort_images_by_distance(mapillary_metadata, keyframe_lat, keyframe_lon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ZOD frame is an instance of `<class 'zod.data_classes.sensor.CameraFrame'>` which has the attributes `filepath`, `time`, `height` and `width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a specific sequence i.e. 000002 we can access all camera_frames like so:  \n",
    "#this will return a list of instances of the cameraFrame class from zod\n",
    "zod_000002_camera_frames = zod_000002.info.get_camera_frames()\n",
    "print(f\"Number of camera frames: {len(zod_000002.info.get_camera_frames())}\")\n",
    "\n",
    "\n",
    "#accessing the keyframe by \n",
    "keyframe = zod_000002.info.get_key_camera_frame()\n",
    "keyframe_image = keyframe.read()\n",
    "plt.imshow(keyframe_image)\n",
    "plt.show()\n",
    "\n",
    "#find keyframe time by\n",
    "print(zod_000002.info.keyframe_time.timestamp())\n",
    "\n",
    "#start time and endtime\n",
    "print('Starttime: ', zod_000002.info.start_time, 'End-time: ', zod_000002.info.end_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to index the frames for convinience, i think it's already sorted tbh but idk in which order, assuming the keyframe is\n",
    "#always going to be the 100th frame\n",
    "\n",
    "# sorted_frames = sorted(zod_000002_camera_frames, key=lambda frame: frame.time.timestamp())\n",
    "# print(sorted_frames)\n",
    "\n",
    "# keyframe_time = zod_000002.info.keyframe_time.timestamp()\n",
    "# print((keyframe_time))\n",
    "\n",
    "# # Step 3: Find the closest frame and its index\n",
    "# closest_frame_index, closest_frame = min(\n",
    "#     enumerate(sorted_frames),\n",
    "#     key=lambda item: abs(item[1].time.timestamp() - keyframe_time)\n",
    "# )\n",
    "\n",
    "# print(f\"Closest Frame Index: {closest_frame_index}\")\n",
    "# print(f\"Closest Frame: {closest_frame}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the pose at a specific time, we have to use the egomotion attribute of the sequence class \n",
    "#and parse the time argument\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "\n",
    "\n",
    "camera_frame = zod_000002_camera_frames[-1]\n",
    "camera_frame_time = camera_frame.time\n",
    "print(camera_frame_time, type(camera_frame_time) )\n",
    "\n",
    "#get poses for a single timestamp\n",
    "poses = zod_000002.ego_motion.get_poses(np.array([camera_frame_time.timestamp()]))\n",
    "\n",
    "print(\"End-time Pose: \\n\", poses)\n",
    "\n",
    "poses = zod_000002.ego_motion.get_poses(np.array([zod_000002.info.keyframe_time.timestamp()]))\n",
    "\n",
    "print(\"KeyFrame Pose: \\n\", poses)\n",
    "\n",
    "#this would be the same as zod_000002.ego_motion.poses[0]\n",
    "#poses = zod_000002.ego_motion.get_poses(np.array([zod_000002.info.start_time.timestamp()])) \n",
    "poses = zod_000002.ego_motion.poses[180]\n",
    "print(\"Start-time Poses: \\n\", poses)\n",
    "\n",
    "#to find the pose for the nth frame --> find the timestamp via frame and then access the pose via ego motion\n",
    "n = 99\n",
    "nth_frame = zod_000002_camera_frames[99]\n",
    "nth_frame_time = nth_frame.time.timestamp()\n",
    "nth_frame_pose = zod_000002.ego_motion.get_poses(np.array([nth_frame_time]))\n",
    "print(n, \"th frame's pose \\n\", nth_frame_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=2, suppress=True)\n",
    "camera_matrix = zod_000002.calibration.cameras[Camera.FRONT].intrinsics[:,0:3]\n",
    "extrinsics = zod_000002.calibration.cameras[Camera.FRONT].extrinsics\n",
    "distortion = zod_000002.calibration.cameras[Camera.FRONT].distortion\n",
    "undistortion = zod_000002.calibration.cameras[Camera.FRONT].undistortion\n",
    "print(camera_matrix, distortion, undistortion)\n",
    "print(extrinsics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supressing unnecessary warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#ensuring i dont exceed cpu limits?\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "\n",
    "from utils import (\n",
    "    getMasterOutout,\n",
    "    scale_intrinsics,\n",
    "    CameraMatrix,\n",
    "    run_pnp,\n",
    "    getImageFromIndex,\n",
    ")\n",
    "\n",
    "keyframe = zod_000002.info.get_key_camera_frame() #serving as anchor\n",
    "query = zod_000002_camera_frames[99]\n",
    "\n",
    "keyframe_image = keyframe.read()\n",
    "query_image = query.read()\n",
    "\n",
    "# Create a figure with 1 row and 2 columns\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(10, 5))  # Adjust figsize as needed\n",
    "\n",
    "# Plot the keyframe image\n",
    "axarr[0].imshow(keyframe_image)\n",
    "axarr[0].set_title(\"Anchor Image\")  # Set title for keyframe image\n",
    "axarr[0].axis('off')  # Hide axis\n",
    "\n",
    "# Plot the query image\n",
    "axarr[1].imshow(query_image)\n",
    "axarr[1].set_title(\"Query Image\")  # Set title for query image\n",
    "axarr[1].axis('off')  # Hide axis\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()\n",
    "\n",
    "master_size = [512,384] #size of image used by mast3r\n",
    "n_matches = 200\n",
    "K_scaled = scale_intrinsics(camera_matrix,query.width, query.height, master_size[0],master_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(query.height, query.width)\n",
    "# print(camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches_im0,filtered_matches_im1,matches_im0, matches_im1, pts3d_im0, pts3d_im1, conf_im0, conf_im1, desc_conf_im0, desc_conf_im1 = getMasterOutout(query.filepath, keyframe.filepath, n_matches,visualizeMatches=False)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def xy_grid(W, H, origin=(0, 0), homogeneous=False):\n",
    "    \"\"\" Create a (H, W, 2) array of pixel coordinates.\n",
    "        If homogeneous is True, adds a third dimension with ones.\n",
    "    \"\"\"\n",
    "    x = np.arange(origin[0], origin[0] + W)\n",
    "    y = np.arange(origin[1], origin[1] + H)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "    \n",
    "    if homogeneous:\n",
    "        grid = np.stack((grid_x, grid_y, np.ones_like(grid_x)), axis=-1)\n",
    "    else:\n",
    "        grid = np.stack((grid_x, grid_y), axis=-1)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def estimate_focal_knowing_depth(pts3d, focal_mode='median', min_focal=0., max_focal=np.inf):\n",
    "    \"\"\" Estimate the camera focal length using reprojection method. \"\"\"\n",
    "    W, H, _ = pts3d.shape\n",
    "    pp = np.array([W / 2, H / 2])  # Principal point\n",
    "\n",
    "    # Centered pixel grid\n",
    "    pixels = xy_grid(W, H) - pp  # Shape: (H, W, 2)\n",
    "\n",
    "    # Flatten points for easier processing\n",
    "    pixels = pixels.reshape(-1, 2)  # Shape: (HW, 2)\n",
    "    pts3d_flat = pts3d.reshape(-1, 3)  # Shape: (HW, 3)\n",
    "\n",
    "    if focal_mode == 'median':\n",
    "        # Direct estimation of focal\n",
    "        u, v = pixels[:, 0], pixels[:, 1]\n",
    "        x, y, z = pts3d_flat[:, 0], pts3d_flat[:, 1], pts3d_flat[:, 2]\n",
    "        \n",
    "        fx_votes = (u * z) / x\n",
    "        fy_votes = (v * z) / y\n",
    "\n",
    "        # Assume square pixels; hence same focal for X and Y\n",
    "        f_votes = np.concatenate((fx_votes[np.newaxis], fy_votes[np.newaxis]), axis=0)\n",
    "        focal = np.nanmedian(f_votes)\n",
    "\n",
    "    elif focal_mode == 'weiszfeld':\n",
    "        # Initialize focal with L2 closed form\n",
    "        xy_over_z = pts3d_flat[:, :2] / pts3d_flat[:, 2][:, np.newaxis]  # Shape: (HW, 2)\n",
    "        xy_over_z[np.isnan(xy_over_z)] = 0  # Handle NaN values\n",
    "\n",
    "        dot_xy_px = (xy_over_z * pixels).sum(axis=1)\n",
    "        dot_xy_xy = (xy_over_z ** 2).sum(axis=1)\n",
    "\n",
    "        focal = dot_xy_px.mean() / dot_xy_xy.mean()\n",
    "\n",
    "        # Iterative re-weighted least-squares\n",
    "        for _ in range(10):\n",
    "            dis = np.linalg.norm(pixels - focal * xy_over_z, axis=1)\n",
    "            w = np.clip(1 / dis, a_min=1e-8, a_max=None)  # Avoid division by zero\n",
    "            \n",
    "            # Update the scaling with the new weights\n",
    "            focal = (w * dot_xy_px).mean() / (w * dot_xy_xy).mean()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid focal_mode: {focal_mode}')\n",
    "\n",
    "    # Clip the focal length based on min and max limits\n",
    "    focal_base = max(H, W) / (2 * np.tan(np.deg2rad(60) / 2))  \n",
    "    focal = np.clip(focal, min_focal * focal_base, max_focal * focal_base)\n",
    "\n",
    "    print(f\"Estimated Focal Length: {focal}\")\n",
    "    return focal\n",
    "\n",
    "# Example usage:\n",
    "# Assuming pts3d_im0 is your point map with shape (W, H, 3)\n",
    "# pts3d_im0 = np.random.rand(480, 640, 3)  # Example initialization\n",
    "focal_length = estimate_focal_knowing_depth(pts3d_im0, focal_mode='weiszfeld', min_focal=0.5, max_focal=3.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches_im0,filtered_matches_im1,matches_im0, matches_im1, pts3d_im0, pts3d_im1, conf_im0, conf_im1, desc_conf_im0, desc_conf_im1 = getMasterOutout(keyframe.filepath, query.filepath, n_matches,visualizeMatches=True)\n",
    "W, H, _ = pts3d_im0.shape\n",
    "K_new = CameraMatrix(focal_length, focal_length, W/2, H/2)\n",
    "# Predicted Transform copied from visloc.py\n",
    "ret_val, transformation = run_pnp(filtered_matches_im1.astype(np.float32), pts3d_im0[filtered_matches_im0[:, 1], filtered_matches_im0[:, 0], :].astype(np.float32), K_new.astype(np.float32),distortion)\n",
    "print(transformation)\n",
    "ret_val, transformation = run_pnp(filtered_matches_im1.astype(np.float32), pts3d_im0[filtered_matches_im0[:, 1], filtered_matches_im0[:, 0], :].astype(np.float32), K_scaled.astype(np.float32),distortion)\n",
    "print(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K_scaled)\n",
    "print(K_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointmap = pts3d_im0[filtered_matches_im0[:, 1], filtered_matches_im0[:, 0], :] #thresholded\n",
    "pointmap_allmatches = pts3d_im0[matches_im0[:, 1], matches_im0[:, 0], :] #unthresholded\n",
    "print(pointmap.shape)\n",
    "\n",
    "\n",
    "keyframe_lidar = zod_000002.get_keyframe_lidar()\n",
    "print(keyframe_lidar)\n",
    "lidar_pointcloud = keyframe_lidar.points\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.scatter(lidar_pointcloud[:, 0], lidar_pointcloud[:, 1], color='red', alpha=0.1,label='LiDAR (from ZOD)')\n",
    "plt.scatter(pointmap_allmatches[:, 0], pointmap_allmatches[:, 2], color='green',alpha=0.5, label='Entire MASt3R Pointmap')\n",
    "plt.scatter(pointmap[:, 0], pointmap[:, 2], color='blue', alpha=0.7,label='Filtered MASt3R Pointmap')\n",
    "\n",
    "# Highlight the origin\n",
    "plt.scatter(0, 0, color='black', s=10, label='Camera', edgecolor='black')\n",
    "\n",
    "\n",
    "# plt.xlim(min(pointmap[:, 0].min(), -1), max(pointmap[:, 0].max(), 5))  # Adjust limits as needed\n",
    "# plt.ylim(min(pointmap[:, 2].min(), -1), max(pointmap[:, 2].max(), 5))  # Adjust limits as needed\n",
    "\n",
    "plt.axhline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "plt.axvline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('2D Plot of X vs Z')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Z Coordinate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# #plt.scatter(pointmap_allmatches[:, 0], pointmap_allmatches[:, 2], color='green',alpha=0.5, label='All matches (x, z)')\n",
    "# plt.scatter(lidar_pointcloud[:, 0], lidar_pointcloud[:, 1], color='red', alpha=0.7,label='Filtered Matches (x, z)')\n",
    "# # Highlight the origin\n",
    "# plt.scatter(0, 0, color='black', s=10, label='Origin (0, 0)', edgecolor='black')\n",
    "# plt.axhline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "# plt.axvline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "\n",
    "# # Add titles and labels\n",
    "# plt.title('2D Plot of X vs Z')\n",
    "# plt.xlabel('X Coordinate')\n",
    "# plt.ylabel('Z Coordinate')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create an output widget to display the plot\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create the figure outside the update function\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.close(fig)  # Prevent immediate display\n",
    "\n",
    "def update_plot(scale_factor):\n",
    "    # Clear previous plot\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Recreate the plot each time\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Scale the pointmap\n",
    "        scaled_pointmap = pointmap * scale_factor\n",
    "        scaled_allmatches = pointmap_allmatches*scale_factor\n",
    "        # Plot LiDAR point cloud\n",
    "        ax.scatter(lidar_pointcloud[:, 0], lidar_pointcloud[:, 1], \n",
    "                   color='red', alpha=0.1, label='LiDAR (from ZOD)')\n",
    "        \n",
    "\n",
    "        ax.scatter(scaled_allmatches[:,0], scaled_allmatches[:,2],color='green',alpha=0.6,label=\"Scaled Complete mast3r pointmap\")\n",
    "        # Plot scaled pointmap\n",
    "        ax.scatter(scaled_pointmap[:, 0], scaled_pointmap[:, 2], \n",
    "                   color='blue', alpha=0.7, label='Scaled Filtered mast3r pointmap')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Origin point\n",
    "        ax.scatter(0, 0, color='black', s=50, label='Camera')\n",
    "        \n",
    "        # Set consistent plot limits\n",
    "        ax.set_xlim(min(pointmap[:, 0].min(), -1), max(pointmap[:, 0].max(), 9))\n",
    "        ax.set_ylim(min(pointmap[:, 2].min(), -1), max(pointmap[:, 2].max(), 5))\n",
    "        \n",
    "        # Grid and lines\n",
    "        ax.axhline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "        ax.axvline(0, color='gray', linewidth=0.5, linestyle='--')\n",
    "        \n",
    "        ax.set_title(f'Pointmap Scaling (Factor: {scale_factor:.2f})')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Z Coordinate')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create slider widget\n",
    "scale_slider = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.1,\n",
    "    max=5.0,\n",
    "    step=0.1,\n",
    "    description='Scale:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Link slider to plot update\n",
    "widgets.interactive(update_plot, scale_factor=scale_slider)\n",
    "\n",
    "# Display widgets\n",
    "display(scale_slider, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
